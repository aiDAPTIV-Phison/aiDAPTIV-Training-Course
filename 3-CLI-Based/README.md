# CLI-Based Lessons

In these lessons, you will learn how to build and experiment with **command-line AI workflows**.  
Each project demonstrates a different aspect of working with Large Language Models (LLMs) using structured prompts, fine-tuning, and retrieval techniques — all from the CLI.  

These lessons build progressively from speaking style models, to multimodal function calling, instruction fine-tuning, evaluation, and retrieval-augmented dataset generation.

---

### Topics

1. [Instruction Fine-Tuning](04-instruction-fine-tuning/README.md)  
   Learn the foundations of fine-tuning models on instruction–response datasets.  

2. [Speaking Style Model](05-speaking-style-model/README.md)  
   Adapt an LLM’s output style for different tones, audiences, and communication needs.  

3. [RAFT Dataset Generation](06-RAFT-Dataset-Generation/README.md)  
   Generate retrieval-augmented datasets to improve factual grounding and domain specialization.  

4. [LLM as a Judge](07-LLM-as-a-judge/README.md)  
   Discover how LLMs can evaluate and grade outputs from other models.  

5. [Vision Function Calling](08-vision-function-calling-model/README.md)  
   Explore how Vision-Language Models (VLMs) can analyze images and trigger structured functions.  

---

### Credits

These lessons were written by the aiDAPTIV+ team.  